from flask import Flask, request, jsonify
import requests
from bs4 import BeautifulSoup
import re
import sqlite3
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
from duckduckgo_search import DDGS  # Updated import

app = Flask(__name__)

# ‚úÖ DuckDuckGo Search Function
def scrape_duckduckgo_search(query, num_results=10):
    try:
        with DDGS() as search:
            results = list(search.text(query, max_results=num_results))
        links = [result["href"] for result in results if "href" in result]
        return links
    except Exception as e:
        print(f"‚ùå Error fetching DuckDuckGo results: {e}")
        return []

# ‚úÖ Keyword Extraction Function
def extract_keywords(text):
    words = re.findall(r'\b[a-zA-Z]{4,}\b', text.lower())  # Only words with 4+ letters
    return list(set(words))  # Remove duplicates

# ‚úÖ Keyword Clustering Function
def cluster_keywords(keywords, num_clusters=5):
    if not keywords:
        return {"error": "No keywords extracted. Try another search term."}

    vectorizer = TfidfVectorizer()
    try:
        X = vectorizer.fit_transform(keywords)
    except ValueError:
        return {"error": "Not enough unique keywords for clustering."}

    kmeans = KMeans(n_clusters=min(num_clusters, len(keywords)), random_state=42, n_init=10)
    clusters = kmeans.fit_predict(X)

    clustered_keywords = {i: [] for i in range(num_clusters)}
    for i, keyword in enumerate(keywords):
        clustered_keywords[clusters[i]].append(keyword)

    return clustered_keywords

# ‚úÖ Store Keywords in SQLite Database
def store_keywords_in_db(keyword_clusters):
    conn = sqlite3.connect("seo_keywords.db")
    cursor = conn.cursor()
    cursor.execute("CREATE TABLE IF NOT EXISTS keywords (cluster INTEGER, keyword TEXT)")

    for cluster, keywords in keyword_clusters.items():
        for keyword in keywords:
            cursor.execute("INSERT INTO keywords (cluster, keyword) VALUES (?, ?)", (cluster, keyword))

    conn.commit()
    conn.close()

# ‚úÖ Flask API Route
@app.route('/scrape', methods=['POST'])
def scrape_and_cluster():
    data = request.json
    query = data.get("query")
    links = scrape_duckduckgo_search(query, num_results=5)  # Reduce from 10 to 5

    if not query:
        return jsonify({"error": "No query provided"}), 400

    print(f"üîç Scraping DuckDuckGo for: {query}")
    links = scrape_duckduckgo_search(query)
    
    if not links:
        return jsonify({"error": "No links found. DuckDuckGo might not have enough data."}), 500

    all_keywords = []
    for link in links:
        try:
            page = requests.get(link, headers={"User-Agent": "Mozilla/5.0"}, timeout=5)
            page.raise_for_status()
            soup = BeautifulSoup(page.text, "html.parser")
            text = soup.get_text()

            if len(text) < 500:
                print(f"‚ö†Ô∏è Skipping {link} (not enough content).")
                continue

            print(f"‚úÖ Scraped {len(text)} characters from {link}")
            keywords = extract_keywords(text)
            all_keywords.extend(keywords)

        except Exception as e:
            print(f"‚ùå Skipping {link} due to error: {e}")

    all_keywords = list(set(all_keywords))
    keyword_clusters = cluster_keywords(all_keywords)

    if "error" in keyword_clusters:
        return jsonify(keyword_clusters), 400

    store_keywords_in_db(keyword_clusters)

    return jsonify({"message": "Scraping & clustering complete", "clusters": keyword_clusters})

# ‚úÖ Run Flask Server
if __name__ == '__main__':
    app.run(debug=True, port=5000)
